<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[数据存储的位置]]></title>
    <url>%2F2019%2F12%2F15%2F%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E7%9A%84%E4%BD%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[数据存储的位置 程序运行时，对象是怎么被安排放置的呢？内存是怎么被分配的呢？根据这个问题，我查阅了《Java编程思想》一书，在22页看到一下内容。有五个不同的地方可以存储数据。 寄存器它是最快的存储区，因为它位于处理器内部，但是寄存器的数量极其有限，所以寄存器是根据需求进行分配的。不能直接进行控制，也不能在程序中感觉到它的存在（在C和C++中允许您向编译器建议寄存器的分配方式） 堆栈位于通用RAM（随机访问存储器）中，通过堆栈指针可以从处理器那里获取直接支持。堆栈指针若向下移动，则分配新的内存；若向上移动，则释放那些内存。这是一种快速有效的分配存储方法，仅次于寄存器。创建程序时，Java系统必须知道存储在堆栈中内所有项的确切生命周期，以便上下移动堆栈指针。这一约束限制了程序的灵活性，所以虽然某些Java数据存储于堆栈中–特别是某些对象引用，但是Java对象并不存储在其中。 堆一种通用的内存池（也位于RAM区），用于存放所有的Java对象。堆不同于堆栈的好处是：编译器不需要知道存储的数据在堆里的存活多长时间。因此，在堆里分配存储有很大的灵活性。当需要一个对象时，只需要new写一行简单的代码，当执行这行代码时，会自动在堆里进行存储分配。当然，这种灵活性也要付出相应的代价：用堆进行存储分配和清理可能会比用堆栈进行存储分配需要更多的时间（Java不可以像C++中那样直接在栈中创建对象）。 常量存储常量值通常直接存放在程序代码内部，这样做时安全的，因为它们永远不会被改变，有时，在嵌入式系统中，常量本身会和其他部分隔离开，所以在这种情况下，可以选择将其存放在ROM（只读存储器）中。 非RAM存储如果数据完全存活于程序之外，那么它可以不受程序的任何控制，在程序没有运行时也可也存在。其中两个基本的例子是流对象和持久化对象。在流对象中，对象转化成字节流，通常被发送给另一台机器。在持久化对象中，对象被存放于磁盘上，因此，即使程序终止，它们仍可以保持自己的状态。这种存储方式的技巧在于：把对象转化成可以存放在其他媒介上的事务，在需要时，可恢复成常规的、基于RAM的对象。Java提供了对轻量级持久化的支持，而诸如JDBC和Hibernate这样的机制提供了更加复杂的对在数据库中储存和读取对象信息的支持。 特例：基本类型在程序设计中经常用到一系列类型，它们需要特殊对待。可以把他们想象成“基本”类型。之所以特殊对待，是因为new将对象存储在堆里，故用new创建一个对象–特别是小的、简单的变量，往往不是很有效。因此，对于这些类型的，Java采用与C和C++相同的方法。也就是说，不用new来创建变量，而是创建一个并非是引用的“自动”变量。这个变量直接存储“值”，并非置于堆栈中，因此更加高效。 Java要确定每种基本类型所占存储空间的大小。他们的大小并不像其他大多数语言那样随机器硬件架构的变化而变化。这种所占存储空间大小的不变性是Java程序比其他大多数语言编写的程序根具有可移植性的原因之一。 基本类型 大小 包装器类型 boolean – Boolean char 16-bit Character byte 8 bits Byte short 16 bits Short int 32 bits Integer long 64 bits Long float 32 bits Float double 64 bits Double void – Void 所有数值类型都有正负号，所以不要去寻找无符号的数值类型。]]></content>
      <categories>
        <category>堆栈</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>堆栈</tag>
        <tag>数据存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql读写分离]]></title>
    <url>%2F2019%2F07%2F05%2Fmysql%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[数据库读写分离对于大型系统或者访问量很高的互联网应用来说，是必不可少的一个重要功能。 从数据库的角度来说，对于大多数应用来说，从集中到分布，最基本的一个需求不是数据存储的瓶颈，而是在于计算的瓶颈，即 SQL 查询的瓶颈，我们知道，正常情况下，Insert SQL 就是几十个毫秒的时间内写入完成，而系统中的大多数 Select SQL 则要几秒到几分钟才能有结果，很多复杂的 SQL，其消耗服务器 CPU 的能力超强，不亚于死循环的威力。在没有读写分离的系统上，很可能高峰时段的一些复杂 SQL 查询就导致数据库服务器 CPU爆表，系统陷入瘫痪，严重情况下可能导致数据库崩溃。因此，从保护数据库的角度来说，我们应该尽量避免没有主从复制机制的单节点数据库。 对于 MySQL 来说，标准的读写分离是主从模式，一个写节点 Master 后面跟着多个读节点，读节点的数量取决于系统的压力，通常是 1-3 个读节点的配置，如下图所示： MySQL 支持更多的主从复制的拓扑关系，如下图所示，但通常我们不会采用双向主从同步以及环状的拓扑：MySQL 主从复制的原理如下： Mysql主从复制的原理如下： 主库上开启二进制日志记录功能。在每次提交事务完成数据更新前，主库将数据更新的事件写入二进制日志中。Mysql会按事务提交的顺序而非每条语句的执行顺序来记录二进制日志。 从库将主库的二进制日志复制到其本地的中继日志中，从库从中继日志中读取事件并在从库中执行，从而实现从库数据的更新。 准备工作主库： 192.168.23.139 从库1：192.168.23.140 从库2：192.168.23.141 每台服务器上安装一个Mysql服务。 实现读写分离 开启主库的二进制日志记录功能。 在主库上，启用 “binary logging” 并配置唯一的 “server ID”（需要重启服务）打开 my.cnf 或者 my.ini 文件，添加如下： 12345[mysqld]// 启用BinaryLog，配置log文件名为 &apos;mysql-bin&apos;log-bin=mysql-bin// 全局唯一的ServerId用来标示服务器在主从集群中的位置server-id=1 这里的 my.cnf 文件的位置可以用 mysqld --help --verbose 看到。 在每个Slave上，配置唯一的 “server ID” （需要重启服务） 12[mysqld]server-id=2 采用同样的方式，给每台Slave服务编号（注意要重启服务！）。从库一般不需要开启BinaryLog，但是可以配置一台Slave开启BinaryLog，留作数据备份之用。 （可选）在主库创建一个用来给 Slave 访问 Master 日志（binarylog）的用户 12mysql&gt; CREATE USER &apos;slave&apos;@&apos;192.168.23.139&apos; IDENTIFIED BY &apos;slavepass&apos;;mysql&gt; GRANT REPLICATION SLAVE ON *.* TO &apos;slave&apos;@&apos;192.168.23.139&apos;; 在Master上创建用户 ‘slave’，并赋予 ‘REPLICATION SLAVE’ 的权限，这样Slave可以通过用户名/密码的方式访问Master 在开始主从复制之前，需要先记录Master上的日志的当前位置（这样Slave才知道从哪儿开始执行BinaryLog中的事件）在Master上执行 mysql &gt; SHOW MASTER STATUS; 可以看到日志的信息（前提是已经启用了BinaryLog，否则是空） 1234567mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000003 | 702 | ifast | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 另外在这步操作时，需要先锁住数据库，避免在这时候产生数据的变化 FLUSH TABLES WITH READ LOCK;，这一步需要非常小心。参考官方文档(https://dev.mysql.com/doc/refman/5.7/en/replication-howto-masterstatus.html) 如果Master上已经有很多数据了，可以先把Master上的数据拷贝到Slave上。这一步的做法太多，如果我们的主从设计是从头开始的，没有遗留数据的烦恼，那么可以略过。 在Slave上配置相关设置，以便告诉Slave如何去连接Master，这包括主机地址，登陆凭证等等执行如下语句，设置相关的环境信息。 123456mysql&gt; CHANGE MASTER TO -&gt; MASTER_HOST=&apos;主库的IP&apos;, -&gt; MASTER_USER=&apos;上面建立的用户名&apos;, -&gt; MASTER_PASSWORD=&apos;上面建立的密码&apos;, -&gt; MASTER_LOG_FILE=&apos;mysql-bin.000003&apos;, -&gt; MASTER_LOG_POS=702; 走完这一圈，整个配置完毕了，如果有新的Slave需要添加到集群中，可以先关闭一台Slave，把数据Copy过来，导入新的Slave在启动配置。 这是基本的主从配置大概步骤，对于生产环境还会有更复杂情况， 全新的Master和Slave，一切从头开始的情况 全新的Master，但是已经有了一些数据需要导入，并配置Slave Master已经配置了Slave，这时候追加一些Slave 对于这些情况，如何处理，详见文档，在此不再赘述。 参考博客和文档 MySQL主从复制（BinaryLog） mycat官方文档]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用mycat对mysql分库分表]]></title>
    <url>%2F2019%2F07%2F04%2F%E4%BD%BF%E7%94%A8mycat%E5%AF%B9mysql%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[前言最近发现项目越做越大，数据也随之越来越多，并发大了就进行负载均衡，搭建项目集群；处理慢了就使用异步请求。所以项目还勉强能撑的下去。但是还有一个问题至今都没有解决，这就是数据库的并发，数据库单表在不影响性能的情况下只能存储200万数据，一旦超过了这个阈值就会降低数据库的性能。目前分库分表方案的产品有很多。如下所示： 而今天要说的Mycat就是基于Cobar实现分库分表的，Mycat的架构其实很好理解，Mycat是代理，Mycat后面就是物理数据库。和Web服务器的Nginx类似。对于使用者来说，访问的都是Mycat，不会接触到后端的数据库。 目前只有1.6.5版本以上支持单库分表。其他版本只支持分库分表。两者是有区别的（被坑惨） 下载进入官网进行下载 Mycat有一个官方文档，初次入门，读起来比较费劲。 安装根据不同的系统选择不同的版本。包括linux、windows、mac,作者考虑还是非常周全的，当然，也有源码版的。（ps:源码版的下载后，只要配置正确，就可以正常运行调试，这个赞一下。） Mycat的安装其实只要解压下载的目录就可以了，非常简单。 安装完成后，目录如下： 目录 说明 bin mycat命令，启动、重启、停止等 catlet catlet为Mycat的一个扩展功能 conf Mycat 配置信息,重点关注 lib Mycat引用的jar包，Mycat是java开发的 logs 日志文件，包括Mycat启动的日志和运行的日志。 配置Mycat的配置文件都在conf目录里面，这里介绍几个常用的文件： 文件 说明 server.xml Mycat的配置文件，设置账号、参数等 schema.xml Mycat对应的物理数据库和数据库表的配置 rule.xml Mycat分片（分库分表）规则 首先配置server.xml vim /etc/home/mycat/conf/server.xml 配置用户名密码和数据库名,表级权限等以后深入的时候再看看（没什么好说的） 配置schema.xml 首先说下这个文件里面的三个大节点 schema节点是用来配置这个数据里面哪些表需要进行分库分表，以及拆分方式。 dataNode节点是用来配置分几个库的，需要分几个库就写几个节点。 dataHost节点是用来配置库的类型、连接方式以及是否要独写分离。（有点模糊不清，具体看官方文档） 1234567891011121314151617181920212223242526272829&lt;?xml version="1.0"?&gt;&lt;!DOCTYPE mycat:schema SYSTEM "schema.dtd"&gt;&lt;mycat:schema xmlns:mycat="http://io.mycat/"&gt; &lt;schema name="ifast" checkSQLschema="true" sqlMaxLimit="1000"&gt; &lt;table name="user" dataNode="dn1,dn2" primaryKey="id" rule="mod-long" /&gt; &lt;/schema&gt; &lt;dataNode name="dn1" dataHost="192.168.23.139" database="ifast" /&gt; &lt;dataNode name="dn2" dataHost="192.168.23.140" database="ifast" /&gt; &lt;dataHost name="192.168.23.139" maxCon="1000" minCon="10" balance="0" writeType="0" dbType="mysql" dbDriver="native" switchType="1" slaveThreshold="100"&gt; &lt;!-- 定时探活 --&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;!-- can have multi write hosts --&gt; &lt;writeHost host="192.168.23.139" url="192.168.23.139:3306" user="root" password="root"&gt; &lt;!-- can have multi read hosts --&gt; &lt;readHost host="192.168.23.139" url="192.168.23.139:3306" user="root" password="root" /&gt; &lt;/writeHost&gt; &lt;/dataHost&gt; &lt;dataHost name="192.168.23.140" maxCon="1000" minCon="10" balance="0" writeType="0" dbType="mysql" dbDriver="native"&gt; &lt;heartbeat&gt;select user();&lt;/heartbeat&gt; &lt;writeHost host="192.168.23.140" url="192.168.23.140:3306" user="root" password="root"&gt;&lt;/writeHost&gt; &lt;!-- can have multi read hosts --&gt; &lt;readHost host="192.168.23.140" url="192.168.23.140:3306" user="root" password="root" /&gt; &lt;/writeHost&gt; &lt;/dataHost&gt;&lt;/mycat:schema&gt; 注意 schema name要和server.xml对应上。 user表设置分库2个，但所以设置2个dataNote。 rule采用取模模式mod-long。表示article 分区配置，按照id进行路由。 writeHost和readHost设为同一数据库。 配置rule.xml 1234567891011&lt;tableRule name="dankufenbiao-mod-long"&gt; &lt;rule&gt; &lt;columns&gt;UserId&lt;/columns&gt; &lt;algorithm&gt;dankufenbiao-mod-long&lt;/algorithm&gt; &lt;/rule&gt;&lt;/tableRule&gt;&lt;function name="dankufenbiao-mod-long" class="io.mycat.route.function.PartitionByMod"&gt; &lt;!-- how many data nodes --&gt; &lt;property name="count"&gt;2&lt;/property&gt;&lt;/function&gt; 启动Mycat启动： 1./mycat start 停止： 1./mycat stop 查看启动状态： 1./mycat status 重启（改变上面的xml配置不用重启，管理端可以重新载入）： 1./mycat restart 查看logs/下的wrapper.log和mycat.log可以查看运行时问题和异常。 mycat启动日志： 1tail -f ../logs/wrapper.log mycat 应用日志： 1tail -f ../logs/mycat.log 测试 mysql创建ifast数据库，user表。 连接mycat, 端口：8066，账号：root, 密码：root 执行sql语句，查看执行过程。 执行sql 查看表 查看192.168.23.139的数据库 查看192.168.23.140的数据库 可以发现Mycat已经自动帮我们将数据分好库了。 具体细节可以参考官方文档，全中文的哦。]]></content>
      <categories>
        <category>mysql</category>
        <category>分库分表</category>
        <category>mycat</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>Mycat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈谈对java的理解]]></title>
    <url>%2F2019%2F07%2F03%2F%E8%B0%88%E8%B0%88%E5%AF%B9Java%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[谈谈对java的理解java本身是面向对象语言，最显著的特征是一次编译，到处运行”，能够非常容易的进行跨平台操作，还有一个特点就是垃圾回收机制，这个特点能够使得开发人员不用太在意内存的分配和回收。我们日常经常会接触到jdk、jre、jvm。下面我们来看看两者的区别。 jdk | java开发工具包jdk里面包含jre，除此之外还包含着开发所需要的一些帮助文档、诊断工具。 jre | java运行时环境jre包含了JVM 和 Java 类库，以及一些模块等。 jvm | java虚拟机jvm内嵌解释器，可以将字节码转换成为最终的机器码。大多数情况使用的 Oracle JDK 提供的 Hotspot jvm ,都提供了 JIT（Just-In-Time）编译器，也就是通常说的动态编译器，JIT能够在运行时将热点代码编译成机器码。 在开发时，记得一定要先导入 jdk 路径，不然是无法编译的。 java程序生命周期 首先开发出源代码 使用javac将源代码进行编译成.class文件 使用java命令将编译后的.class文件运行 最后jvm会自动将.class文件转换成最终的机器码。 运行结束 面向对象的三大特征 封装、继承、多态 java目前就先总结这里。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于storm处理kafka数据]]></title>
    <url>%2F2019%2F07%2F03%2F%E5%9F%BA%E4%BA%8Estorm%E5%A4%84%E7%90%86kafka%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[背景最近有个项目需要将kafka中的数据进行去重然后保存到Mongo中，由于数据量太大所以首选使用storm进行实时处理。这里主要记录是关于kafka和storm的整合。 关于storm Storm是一个免费开源、分布式、高容错的实时计算系统。Storm令持续不断的流计算变得容易，弥补了Hadoop批处理所不能满足的实时要求。Storm经常用于在实时分析、在线机器学习、持续计算、分布式远程调用和ETL等领域。Storm的部署管理非常简单，而且，在同类的流式计算工具，Storm的性能也是非常出众的。 关于kafka Kafka是一种高吞吐量的分布式发布订阅消息系统。 项目搭建使用maven进行jar包集成 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;kafka.version&gt;1.0.0&lt;/kafka.version&gt; &lt;storm.version&gt;1.2.1&lt;/storm.version&gt; &lt;fastjson.version&gt;1.2.41&lt;/fastjson.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--kafka jar --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka_2.12&lt;/artifactId&gt; &lt;version&gt;$&#123;kafka.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;$&#123;kafka.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-streams&lt;/artifactId&gt; &lt;version&gt;$&#123;kafka.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--storm相关jar --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.storm&lt;/groupId&gt; &lt;artifactId&gt;storm-core&lt;/artifactId&gt; &lt;version&gt;$&#123;storm.version&#125;&lt;/version&gt; &lt;!--排除相关依赖 --&gt; &lt;exclusions&gt; &lt;!--&lt;exclusion&gt;--&gt; &lt;!--&lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;--&gt; &lt;!--&lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt;--&gt; &lt;!--&lt;/exclusion&gt;--&gt; &lt;!--&lt;exclusion&gt;--&gt; &lt;!--&lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;--&gt; &lt;!--&lt;artifactId&gt;log4j-1.2-api&lt;/artifactId&gt;--&gt; &lt;!--&lt;/exclusion&gt;--&gt; &lt;!--&lt;exclusion&gt;--&gt; &lt;!--&lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;--&gt; &lt;!--&lt;artifactId&gt;log4j-web&lt;/artifactId&gt;--&gt; &lt;!--&lt;/exclusion&gt;--&gt; &lt;!--&lt;exclusion&gt;--&gt; &lt;!--&lt;groupId&gt;org.slf4j&lt;/groupId&gt;--&gt; &lt;!--&lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;--&gt; &lt;!--&lt;/exclusion&gt;--&gt; &lt;!--&lt;exclusion&gt;--&gt; &lt;!--&lt;artifactId&gt;ring-cors&lt;/artifactId&gt;--&gt; &lt;!--&lt;groupId&gt;ring-cors&lt;/groupId&gt;--&gt; &lt;!--&lt;/exclusion&gt;--&gt; &lt;/exclusions&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.storm&lt;/groupId&gt; &lt;artifactId&gt;storm-kafka&lt;/artifactId&gt; &lt;version&gt;$&#123;storm.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Protocol Buffers --&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.protobuf&lt;/groupId&gt; &lt;artifactId&gt;protobuf-java&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.codahale.metrics/metrics-core --&gt; &lt;dependency&gt; &lt;groupId&gt;com.codahale.metrics&lt;/groupId&gt; &lt;artifactId&gt;metrics-core&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--fastjson 相关jar --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;$&#123;fastjson.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MongoDB连接驱动 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mongodb&lt;/groupId&gt; &lt;artifactId&gt;mongo-java-driver&lt;/artifactId&gt; &lt;version&gt;3.7.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/redis.clients/jedis --&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Topology创建一个启动类，程序启动时最先启动它。 并在main方法中声明config对象，配置nimbus主机、zookeeper集群、worker数量等。 声明TopologyBuilder类最要是用来配置spout和bolt（spout和bolt使用自定义的类，方便数据处理） 如果是在本地启动则声明LocalCluster对象，如果是在生产环境中使用需要提交至Nimbus服务器上启动。 123456789101112131415161718192021222324252627282930313233343536373839public class TopologyMain &#123; static Logger logger = LoggerFactory.getLogger(TopologyMain.class); public static void main(String[] args)&#123; Config config = new Config(); config.put(Config.NIMBUS_HOST, Constants.STORM_SERVER); //配置nimbus连接主机地址，比如：192.168.10.1 config.put(Config.NIMBUS_THRIFT_PORT, 6627);//配置nimbus连接端口，默认 6627 config.put(Config.STORM_ZOOKEEPER_SERVERS, Arrays.asList(Constants.ZKSERVERS)); //配置zookeeper连接主机地址，可以使用集合存放多个 config.put(Config.STORM_ZOOKEEPER_PORT, 2181); //配置zookeeper连接端口，默认2181 config.setDebug(true); config.setNumWorkers(30); config.setMaxSpoutPending(50); TopologyBuilder builder = new TopologyBuilder(); builder.setSpout("spout", new KafkaDataSpout(), 3); builder.setBolt("bolt", new DataParseBolt(), 3).shuffleGrouping("spout"); try &#123; // 运行拓扑 // 有参数时，表示向集群提交作业，并把第一个参数当做topology名称 // 没有参数时，本地提交 if (args != null &amp;&amp; args.length &gt; 0) &#123; logger.info("运行远程模式"); StormSubmitter.submitTopology(args[0], config, builder.createTopology()); &#125; else &#123; // 启动本地模式 logger.info("运行本地模式"); LocalCluster cluster = new LocalCluster(); cluster.submitTopology("TopologyApp", config, builder.createTopology());// Thread.sleep(20000); // //关闭本地集群// cluster.shutdown(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; Spout可以把它看出生产者，专门用来获取数数据的，由于我们的数据来源于kafka中，所以需要在这里连接kafka并将数据下发至bolt中。 初始化kafka，获取到kafka连接对象。 读取kafka数据，由于kafka中存储的是Protocol Buffer格式的数据，所以使用byte方式读取，准备在bolt中解析。 下发至bolt 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * @author pancm * @Title: KafkaDataSpout * @Description: 从kafka获取新增数据 * @Version:1.0.0 * @date 2018年4月19日 */public class KafkaDataSpout extends BaseRichSpout &#123; /** * */ private static final long serialVersionUID = -2548451744178936478L; private static final Logger logger = LoggerFactory.getLogger(KafkaDataSpout.class); private SpoutOutputCollector collector; private KafkaConsumer&lt;String, byte[]&gt; consumer; private ConsumerRecords&lt;String, byte[]&gt; msgList; public void open(Map map, TopologyContext arg1, SpoutOutputCollector collector) &#123; kafkaInit(); this.collector = collector; &#125; public void nextTuple() &#123; for (; ; ) &#123; try &#123; msgList = consumer.poll(1); if (null != msgList &amp;&amp; !msgList.isEmpty()) &#123; for (ConsumerRecord&lt;String, byte[]&gt; record : msgList)&#123; // 原始数据 byte[] value = record.value(); if (value == null || value.length == 0) &#123; return; &#125; this.collector.emit(new Values(value)); consumer.commitAsync(); &#125; &#125; else &#123; TimeUnit.SECONDS.sleep(1); logger.info("未拉取到数据..."); &#125; &#125; catch (Exception e) &#123; logger.error("消息队列处理异常:", e); try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e1) &#123; logger.error("暂停失败!", e1); &#125; &#125; &#125; &#125; public void declareOutputFields(OutputFieldsDeclarer declarer) &#123; declarer.declare(new Fields(Constants.FIELD)); &#125; /** * 初始化kafka配置 */ private void kafkaInit() &#123; Properties props = new Properties(); props.put("bootstrap.servers", Constants.KAFKA_SERVERS); props.put("max.poll.records", 10); props.put("enable.auto.commit", false); props.put("group.id", "groupA"); props.put("auto.offset.reset", "earliest"); props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer"); props.put("value.deserializer", "org.apache.kafka.common.serialization.ByteArrayDeserializer"); consumer = new KafkaConsumer&lt;String, byte[]&gt;(props); String topic = Constants.TOPIC_NAME; this.consumer.subscribe(Arrays.asList(topic)); logger.info("消息队列[" + topic + "] 开始初始化..."); &#125; Bolt可以把他看作是消费者，它是专门用来处理数据的。获取到spout下发的数据后，进行解析处理，然后将数据去重在保存到mongo中。 获取到spout数据。 解析protocol buffer数据，可以参考官网提供的示例。官网：Java示例 使用redis进行去重 保存至Mongo 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115/** * @Title: DataParseBolt * @Description: * 写入数据的bolt * @Version:1.0.0 * @author pancm * @date 2018年4月19日 */public class DataParseBolt extends BaseRichBolt&#123; private static final long serialVersionUID = 6542256546124282695L; private static final Logger logger = LoggerFactory.getLogger(DataParseBolt.class); @SuppressWarnings("rawtypes") public void prepare(Map map, TopologyContext arg1, OutputCollector collector) &#123; &#125; public void execute(Tuple tuple) &#123; byte[] bytes = tuple.getBinaryByField(Constants.FIELD); //业务逻辑处理,这里就简单的打印一下 doSomeThing(bytes);// logger.info("接收的消息:&#123;&#125;", new String(bytes)); &#125; /** * cleanup是IBolt接口中定义,用于释放bolt占用的资源。 * Storm在终止一个bolt之前会调用这个方法。 */ @Override public void cleanup() &#123;&#125; public void declareOutputFields(OutputFieldsDeclarer arg0) &#123; &#125; private void doSomeThing(byte[] value)&#123; byte[] bytes = DataUtil.subByte(value, 0, Constants.LEN); int sum = DataUtil.byteArrayToInt(bytes); // 这一条消息里面有 sum条数据 int offset = Constants.LEN; //byte数组偏移量 for (int i = 1; i &lt;= sum; i ++)&#123; byte[] dataLenth = DataUtil.subByte(value, offset, Constants.LEN); // data数据的长度 int i1 = DataUtil.byteArrayToInt(dataLenth); // data数据的长度 offset += Constants.LEN; byte[] data = DataUtil.subByte(value, offset, i1); offset += i1; // data 转 对象 ， 祝好运 try &#123; SensorLog.SENSOR_LOG sensorLog = SensorLog.SENSOR_LOG.parseFrom(data); parseResult(sensorLog); &#125; catch (InvalidProtocolBufferException e) &#123; logger.info("sensorLog对象转换错误：&#123;&#125;", e.getMessage()); &#125; &#125; &#125; /** * 处理转换后的结果 * 然后进行保存 * @param sensorLog 结果对象 */ private static void parseResult(SensorLog.SENSOR_LOG sensorLog)&#123; ParseResult parseResult = new ParseResult(); SensorLog.WEBLOG skyeyeWeblog = sensorLog.getSkyeyeWeblog(); String uri = UrlUtils.decode(skyeyeWeblog.getUri().toStringUtf8()); String urlPath = "http://" + skyeyeWeblog.getHost()+ uri; URL url = null; try &#123; url = new URL(urlPath); &#125; catch (MalformedURLException e) &#123; logger.info("url error: &#123;&#125;", urlPath); return; &#125; // 过滤规则 （没有问号但又&amp; || 以？结尾 || host为空 || 状态码不以2和3开头） if (uri.indexOf("?") == -1 &amp;&amp; uri.contains("&amp;") || uri.endsWith("?") || url.getHost() == null || "".equals(url.getHost())) return; if (skyeyeWeblog.getStatus() &lt; 200 || skyeyeWeblog.getStatus() &gt;= 400) return; switch (skyeyeWeblog.getMethod())&#123; case "GET": parseResult.setMethod("GET"); parseResult.setRawQuery(url.getQuery() == null ? "" : url.getQuery()); // uri问号后面就是参数 break; case "POST": parseResult.setMethod("POST"); parseResult.setRawQuery(skyeyeWeblog.getData().toStringUtf8()); break; default: break; &#125; parseResult.setHost(url.getProtocol() + "://" + url.getHost()); parseResult.setContentType(skyeyeWeblog.getContentType()); parseResult.setVendorId(skyeyeWeblog.getVendorId()); parseResult.setPath(url.getPath()); parseResult.setStatusCode(skyeyeWeblog.getStatus()); parseResult.setUrl(url.toString()); String filterQueryKey = ""; UrlUtil.UrlEntity parse = UrlUtil.parse(parseResult.getUrl()); if (parse.params != null &amp;&amp; parse.params.size() &gt; 0)&#123; filterQueryKey = String.join("&amp;", parse.params.keySet()); &#125; Result result = new Result(); result.setTime(new Date().getTime()); result.setParseResult(parseResult); String filterUrl = url.getProtocol() + "://" + url.getHost() + NewPatterns.parsePattern(parseResult.getPath()) + "?" + filterQueryKey; result.setUniqueUrl(parseResult.getUrl()); result.setRegexPath(filterUrl); result.setUniqueMd5(MD5Util.MD5(filterUrl)); Jedis jedis = JedisManager.getJedis(); // 去重 + 保存 Boolean bool = jedis.hexists(Constants.RedisConfig.KEY, result.getUniqueMd5()); if (!bool)&#123; jedis.hset(Constants.RedisConfig.KEY, result.getUniqueMd5(), "1"); MongoManager.insert(result); &#125; JedisManager.close(jedis); &#125; 打包部署 使用storm官方提供的maven插件进行打包。 12345678910111213&lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;com.path.to.main.Class&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; 然后运行 mvn assembly:assembly 来获取适当打包的 jar. 确保您 排除了 Storm jar, 因为群集已经在类路径上有 Storm。 排除Storm.jar 在项目的target目录下找到已经打包好的jar文件。 插件会自动生成两种jar文件，而我们需要的是包含第三方jar包的jar文件。 将文件上传至nimbus服务器上进行部署 scp storm-1.0-SNAPSHOT-jar-with-dependencies.jar root@192.168.23.139:/home 将文件移入storm的bin目录下，使用以下命令进行部署运行 ./storm jar jar文件 启动类的路径 topology名称 ./storm jar storm-1.0-SNAPSHOT-jar-with-dependencies.jar com.weijunzhe.TopologyMain kafka_storm 输出以下内容说明部署成功 1234567891011121314151617[root@redis bin]# ./storm jar storm-1.0-SNAPSHOT-jar-with-dependencies.jar com.weijunzhe.TopologyMain storm-kafkaRunning: java -client -Ddaemon.name= -Dstorm.options= -Dstorm.home=/home/storm/apache-storm-1.2.2 -Dstorm.log.dir=/home/storm/apache-storm-1.2.2/logs -Djava.library.path=/usr/local/lib:/opt/local/lib:/usr/lib -Dstorm.conf.file= -cp /home/storm/apache-storm-1.2.2/*:/home/storm/apache-storm-1.2.2/lib/*:/home/storm/apache-storm-1.2.2/extlib/*:storm-1.0-SNAPSHOT-jar-with-dependencies.jar:/home/storm/apache-storm-1.2.2/conf:/home/storm/apache-storm-1.2.2/bin -Dstorm.jar=storm-1.0-SNAPSHOT-jar-with-dependencies.jar -Dstorm.dependency.jars= -Dstorm.dependency.artifacts=&#123;&#125; com.weijunzhe.TopologyMain storm-kafka427 [main] INFO c.w.TopologyMain - 运行远程模式526 [main] WARN o.a.s.u.Utils - STORM-VERSION new 1.2.2 old null546 [main] INFO o.a.s.StormSubmitter - Generated ZooKeeper secret payload for MD5-digest: -9189552336942843022:-6760854273759919878604 [main] WARN o.a.s.u.NimbusClient - Using deprecated config nimbus.host for backward compatibility. Please update your storm.yaml so it only has config nimbus.seeds629 [main] INFO o.a.s.u.NimbusClient - Found leader nimbus : redis:6627642 [main] INFO o.a.s.s.a.AuthUtils - Got AutoCreds []642 [main] WARN o.a.s.u.NimbusClient - Using deprecated config nimbus.host for backward compatibility. Please update your storm.yaml so it only has config nimbus.seeds644 [main] INFO o.a.s.u.NimbusClient - Found leader nimbus : redis:6627658 [main] INFO o.a.s.StormSubmitter - Uploading dependencies - jars...659 [main] INFO o.a.s.StormSubmitter - Uploading dependencies - artifacts...659 [main] INFO o.a.s.StormSubmitter - Dependency Blob keys - jars : [] / artifacts : []664 [main] INFO o.a.s.StormSubmitter - Uploading topology jar storm-1.0-SNAPSHOT-jar-with-dependencies.jar to assigned location: /home/storm/apache-storm-1.2.2/localdir/nimbus/inbox/stormjar-0e80a2ae-e7ab-4b7f-b84c-ef821ac11ab5.jar856 [main] INFO o.a.s.StormSubmitter - Successfully uploaded topology jar to assigned location: /home/storm/apache-storm-1.2.2/localdir/nimbus/inbox/stormjar-0e80a2ae-e7ab-4b7f-b84c-ef821ac11ab5.jar857 [main] WARN o.a.s.u.Utils - STORM-VERSION new 1.2.2 old 1.2.2981 [main] INFO o.a.s.StormSubmitter - Finished submitting topology: storm-kafka 如果出现以下内容，说明没有找到启动类的main方法，请检查启动类的路径是否输入正确。 123Running: java -client -Ddaemon.name= -Dstorm.options= -Dstorm.home=/home/storm/apache-storm-1.2.2 -Dstorm.log.dir=/home/storm/apache-storm-1.2.2/logs -Djava.library.path=/usr/local/lib:/opt/local/lib:/usr/lib -Dstorm.conf.file= -cp /home/storm/apache-storm-1.2.2/*:/home/storm/apache-storm-1.2.2/lib/*:/home/storm/apache-storm-1.2.2/extlib/*:storm-1.0-SNAPSHOT-jar-with-dependencies.jar:/home/storm/apache-storm-1.2.2/conf:/home/storm/apache-storm-1.2.2/bin -Dstorm.jar=storm-1.0-SNAPSHOT-jar-with-dependencies.jar -Dstorm.dependency.jars= -Dstorm.dependency.artifacts=&#123;&#125; com.weijunzhe.TopologyMa storm-kafkaError: Could not find or load main class com.weijunzhe.TopologyMaYou have new mail in /var/spool/mail/root 如果出现本地模式启动 则表示你没有输入topology的名称，需要在启动命令后输入topology名称。 在storm的web界面中查看topology运行状态]]></content>
      <categories>
        <category>java开发</category>
      </categories>
      <tags>
        <tag>storm</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Storm集群搭建]]></title>
    <url>%2F2019%2F06%2F28%2FStorm%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[环境 版本: Storm 1.2.2 java: jdk 1.7 系统：centos7 zookeeper-3.4.14 分别在三台机器上部署 server0 192.168.23.139(Master) server1 192.168.23.140(Supervisor) server2 192.168.23.141(Supervisor) 安装Storm之前，需要先安装zookeeper,请看我之前的博客 Zookeeper集群搭建 下载路径apache-storm-1.2.2.tar.gz 解压将Storm解压到指定目录 1tar -zxvf apache-storm-1.2.2.tar.gz -C /usr/local 修改配置文件修改conf目录中的storm.yaml文件： 1234567891011121314storm.local.dir: &quot;/usr/local/apache-storm-1.2.2/localdir&quot;storm.zookeeper.port: 2181storm.zookeeper.servers: - &quot;server0&quot; - &quot;server1&quot; - &quot;server2&quot;nimbus.seeds: [&quot;server0&quot;]ui.host: 0.0.0.0ui.port: 8088supervisor.slots.ports: - 6700 - 6701 - 6702 - 6703 在设置参数时，不要使用制表符代替空格。 新建目录1mkdir -p /usr/local/apache-storm-1.2.2/localdir 分发文件12scp -r apache-storm-1.2.2 root@server1:/usr/localscp -r apache-storm-1.2.2 root@server2:/usr/local 启动Storm先启动Zookeeper 在server0（Master）上启动nimbus进程 在Storm的bin目录下执行 1nohup ./storm nimbus &amp; 在server0（Master）上启动UI进程 1nohup ./storm ui &amp; 在所有的supervisor上启动supervisor进程 1nohup ./storm supervisor &amp; 启动web登录查看 http://192.168.23.139:8088 注意：启动时加载很慢，请耐心等待。如果没有启动成功，请查看日志。 可能遇到的问题 web不能正常登录 如果登录web的时候，一直显示loading summary，看不到任何明确的信息。先查看logs目录下的日志，一般是显示超时之类的。这应该是某个进程没有启动成功。对集群中的每个节点使用jps命令查看，看是否有显示config_value，config_value是没有启动成功，对该节点重新启动（不是重启主机，是重启sotrm相关进程）。 如果登录web的时候，网页进不去，看不到内容（连loading summary都看不到），一直在链接，也没有提示超时之类的，换浏览器也不行，对所有节点全部重启（不是重启主机，是重启sotrm相关进程）。 如果kill或者kill -9都杀不掉某个进程，我暂时没有找到解决方法，直接重启主机。 如果登录进去可以看到nimbus或者supervisor等信息，某些信息看不到（一直显示loading summary）。可以换个浏览器试试，用谷歌可以正常显示，用的360就不行，而且360每次都显示loading summary。 nimbus或supervisor不能启动 虽然执行了启动命令但是在命令执行完后进程又退出了。首先查看日志。如果是nimbus不能启动，查看nimbus.log。 一般会有这样的信息： 12342019-06-26 10:02:30.982 o.a.s.s.o.a.z.ClientCnxn main-SendThread(server0:2181) [INFO] Socket connection established to Desktop/192.168.23.139:2181, initiating session2019-06-26 10:02:30.986 o.a.s.s.o.a.z.ClientCnxn main-SendThread(server0:2181) [INFO] Unable to read additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect2019-06-26 10:02:31.311 o.a.s.s.o.a.z.ClientCnxn main-SendThread(server0:2181) [INFO] Opening socket connection to server Server1/192.168.23.139:2181. Will not attempt to authenticate using SASL (unknown error) 这个是zkServer挂掉了。虽然执行jps可以看到QuorumPeerMain还在，但是实际上zkServer已经挂了。 这个是zkServer存活数只有一半（或小于）配置数引起的。比如zookeeper部署了4台，但是只起了2台，默认zkServer状态就是挂掉了。当再起一台zkServer，即存活数达到3台，超过1半了，就可以查看状态了。也就是说zkServer集群已经运行起来了。 前面的问题也就解释通了，虽然可以看到zkServer进程，但是因为存活数不足，默认zkServer没有运行起来，所以也就无法启动nimbus或者supervisor了。 storm集群启动停止脚本 其他参考： 转载自：关于storm nimbus &gt; /dev/null 2&gt;&amp;1 如图所示：bin/storm nimbus会有两个输出，一个标准输出，一个错误输出 2&gt;&amp;1的作用是将 2即错误输出 的内容重定向到&amp;1即标准输出中，然后&gt;/dev/null是将两者的结果输入到/dev/null中，相当于抛弃掉。至于最后一个&amp;，因为storm会一直运行，不会自动停掉，页面上就会不停的有内容。&amp;的作用就是将storm拿到后台执行。]]></content>
      <categories>
        <category>集群搭建</category>
      </categories>
      <tags>
        <tag>storm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka集群搭建]]></title>
    <url>%2F2019%2F06%2F28%2FKafka%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[Kafka介绍Kafka是一种高吞吐量的分布式发布订阅消息系统，有如下特性： 通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。 高吞吐量：即使是非常普通的硬件kafka也可以支持每秒数十万的消息。 支持通过kafka服务器和消费机集群来分区消息。 支持Hadoop并行数据加载。 Kafka的目的是提供一个发布订阅解决方案，它可以处理消费者规模的网站中的所有动作流数据。 这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。 这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。 对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。 kafka是用Scala编写，用scalac编译器把源文件编译成Java的class文件（即在JVM上运行的字节码），因此Scala是基于JVM的语言，所以使用Kafka需要机器上游JVM支持，本文使用jdk版本为jdk-7u75. 以3台为例，如果是一个Follower宕机，还有2台服务器提供访问，因为Zookeeper上的数据是有多个副本的，数据并不会丢失，如果是一个Leader宕机，Zookeeper会选举出新的Leader。为什么是奇数台，如果Zookeeper 集群是3台，允许宕机1台，如果是4台，同样是允许1台宕机，因为选举算法要求”超过半数“，所以多出的一台没有意义。 配置步骤Kafka自带了zookeeper，但是一般集群都会有zk，因此使用集群已有的zookeeper。本次不使用Kafka自带的zookeeper。 下载kafka_2.11-0.10.0.0.tgz 配置文件 server.properties 12345678910111213141516171819202122232425262728293031323334353637############################# Server Basics ############################## 唯一标识一个broker.broker.id=1############################# Socket Server Settings ##############################绑定服务监听的地址和端口，要填写hostname -i 出来的地址，否则可能会绑定到127.0.0.1,producer可能会发不出消息listeners=PLAINTEXT://192.168.23.139:9092#broker对producers和consumers服务的地址和端口，如果没有配置，使用listeners的配置，本文没有配置该项#advertised.listeners=PLAINTEXT://your.host.name:9092# 处理网络请求的线程数num.network.threads=3# 处理磁盘I/O的线程数num.io.threads=8# socket server的发送buffer大小 (SO_SNDBUF) socket.send.buffer.bytes=102400# socket server的接收buffer大小 (SO_RCVBUF)socket.receive.buffer.bytes=102400#一个请求的最大size，用来保护防止oomsocket.request.max.bytes=104857600############################# Log Basics ##############################存放日志和消息的目录，可以是用逗号分开的目录，同样不推荐使用/tmplog.dirs=/usr/local/kafka_2.11-2.3.0/logs#每个topic默认partitions的数量，数量较大表示消费者可以有更大的并行度。num.partitions=2# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.# This value is recommended to be increased for installations with data dirs located in RAID array.num.recovery.threads.per.data.dir=1#日志的过期时间，超过后被删除，单位小时log.retention.hours=168#一个日志文件最大大小，超过会新建一个文件log.segment.bytes=1073741824#根据过期策略检查过期文件的时间间隔，单位毫秒log.retention.check.interval.ms=300000############################# Zookeeper ##############################Zookeeper的连接配置，用逗号隔开，也可以用192.168.23.139:2181/kakfa这样的方式指定kafka数据在zk中的根目录zookeeper.connect=192.168.23.139:2181,192.168.23.140:2181,192.168.23.141:2181# 连接zk的超时时间zookeeper.connection.timeout.ms=6000 主要配置文件为server.properties，对于producer和consumer分别有producer.properties和consumer.properties，但是一般不需要单独配置，可以从server.properties中读取。 启动各个节点启动各节点，分发此配置文件，修改broker.id和listeners地址，建立相应的目录。 123[root@server0 kafka_2.11-2.3.0]# ./bin/kafka-server-start.sh -daemon config/server.properties[root@server1 kafka_2.11-2.3.0]# ./bin/kafka-server-start.sh -daemon config/server.properties[root@server2 kafka_2.11-2.3.0]# ./bin/kafka-server-start.sh -daemon config/server.properties -daemon放在后台运行。 验证是否成功 创建一个topic名为my-test 12[root@server0 kafka_2.11-2.3.0]# bin/kafka-topics.sh --create --zookeeper 172.23.8.144:2181 --replication-factor 3 --partitions 1 --topic my-testCreated topic &quot;my-test&quot;. 发送消息，ctrl+c终止 123[root@server0 kafka_2.11-2.3.0]# bin/kafka-console-producer.sh --broker-list 172.23.8.144:9092 --topic my-test今天是个好日子hello 另一台机器消费 123[root@server0 kafka_2.11-2.3.0]# bin/kafka-console-consumer.sh --zookeeper slave3:2181 --from-beginning --topic my-test今天是个好日子hello 继续发送消息则在消费者终端会一直出现新产生的消息。至此,kafka集群搭建成功。 Kafka HelloWorld在kafka的手册中给出了java版的producer和cousumer的代码示例.修改下地址，逗号隔开，该地址是集群的子集，用来探测集群。 Producer代码示例 123456789101112131415161718192021222324252627import java.util.Properties;import org.apache.kafka.clients.producer.KafkaProducer;import org.apache.kafka.clients.producer.ProducerRecord;public class Producer &#123; public static void main(String[] args) &#123; Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, &quot;192.168.23.139:9092,192.168.23.140:9092,192.168.23.141:9092&quot;);//该地址是集群的子集，用来探测集群。 props.put(&quot;acks&quot;, &quot;all&quot;);// 记录完整提交，最慢的但是最大可能的持久化 props.put(&quot;retries&quot;, 3);// 请求失败重试的次数 props.put(&quot;batch.size&quot;, 16384);// batch的大小 props.put(&quot;linger.ms&quot;, 1);// 默认情况即使缓冲区有剩余的空间，也会立即发送请求，设置一段时间用来等待从而将缓冲区填的更多，单位为毫秒，producer发送数据会延迟1ms，可以减少发送到kafka服务器的请求数据 props.put(&quot;buffer.memory&quot;, 33554432);// 提供给生产者缓冲内存总量 props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);// 序列化的方式， // ByteArraySerializer或者StringSerializer props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props); for (int i = 0; i &lt; 10000; i++) &#123; // 三个参数分别为topic, key,value，send()是异步的，添加到缓冲区立即返回，更高效。 producer.send(new ProducerRecord&lt;String, String&gt;(&quot;my-topic&quot;, Integer.toString(i), Integer.toString(i))); &#125; producer.close(); &#125;&#125; Consumer代码示例 123456789101112131415161718192021222324252627282930import java.util.Arrays;import java.util.Properties;import org.apache.kafka.clients.consumer.ConsumerRecord;import org.apache.kafka.clients.consumer.ConsumerRecords;import org.apache.kafka.clients.consumer.KafkaConsumer;public class Consumer &#123; public static void main(String[] args) &#123; Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, &quot;192.168.23.139:9092,192.168.23.140:9092,192.168.23.141:9092&quot;);// 该地址是集群的子集，用来探测集群。 props.put(&quot;group.id&quot;, &quot;test&quot;);// cousumer的分组id props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);// 自动提交offsets props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);// 每隔1s，自动提交offsets props.put(&quot;session.timeout.ms&quot;, &quot;30000&quot;);// Consumer向集群发送自己的心跳，超时则认为Consumer已经死了，kafka会把它的分区分配给其他进程 props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);// 反序列化器 props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props); consumer.subscribe(Arrays.asList(&quot;my-topic&quot;));// 订阅的topic,可以多个 while (true) &#123; ConsumerRecords&lt;String, String&gt; records = consumer.poll(100); for (ConsumerRecord&lt;String, String&gt; record : records) &#123; System.out.printf(&quot;offset = %d, key = %s, value = %s&quot;, record.offset(), record.key(), record.value()); System.out.println(); &#125; &#125; &#125;&#125; 分别运行即可。看到comsumer打印出消息日志。 以上参考博客：https://blog.csdn.net/z769184640/article/details/51585419]]></content>
      <categories>
        <category>集群搭建</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper集群搭建]]></title>
    <url>%2F2019%2F06%2F28%2FZookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[搭建环境 操作系统：Centos7 java: jdk 1.7+ 版本：3.4.14 下载路径zookeeper-3.4.14 将下载好的tar.gz包放入/home路径下。 准备服务器 server0 192.168.23.139 server1 192.168.23.140 server2 192.168.23.141 解压 在/home路径下，执行以下命令 1tar -zxvf zookeeper-3.4.14.tar.gz -C /usr/local 修改配置文件进入zookeeper的conf文件夹下，将zoo_sample.cfg配置文件复制为zoo.cfg文件，并使用vim命令修改zoo.cfg配置 1234cd /usr/local/zookeeper-3.4.14cd confcp zoo_sample.cfg zoo.cfgvim zoo.cfg #修改配置文件 修改如下： 1234dataDir=/usr/local/zookeeper-3.4.14/dataserver.0=192.168.23.139:2888:3888server.1=192.168.23.140:2888:3888server.2=192.168.23.141:2888:3888 具体修改如图所示： 创建zookeeper标识 在zookeeper目录下创建data文件夹 12345678910111213141516171819202122232425262728[root@localhost zookeeper-3.4.14]# lltotal 1676drwxr-xr-x. 2 2002 2002 223 Jun 25 07:22 bin-rw-rw-r--. 1 2002 2002 97426 Mar 6 11:50 build.xmldrwxr-xr-x. 2 2002 2002 92 Jun 26 00:18 confdrwxr-xr-x. 2 2002 2002 4096 Mar 6 12:10 dist-maven-rw-rw-r--. 1 2002 2002 1709 Mar 6 11:50 ivysettings.xml-rw-rw-r--. 1 2002 2002 10742 Mar 6 11:50 ivy.xmldrwxr-xr-x. 4 2002 2002 4096 Mar 6 12:09 lib-rw-rw-r--. 1 2002 2002 11970 Mar 6 11:50 LICENSE.txt-rw-rw-r--. 1 2002 2002 3132 Mar 6 11:50 NOTICE.txt-rw-rw-r--. 1 2002 2002 31622 Mar 6 11:50 pom.xml-rw-rw-r--. 1 2002 2002 1765 Mar 6 11:50 README.md-rw-rw-r--. 1 2002 2002 1770 Mar 6 11:50 README_packaging.txtdrwxr-xr-x. 3 2002 2002 22 Mar 6 11:50 src-rw-rw-r--. 1 2002 2002 1515359 Mar 6 11:50 zookeeper-3.4.14.jar-rw-rw-r--. 1 2002 2002 836 Mar 6 12:10 zookeeper-3.4.14.jar.asc-rw-rw-r--. 1 2002 2002 33 Mar 6 11:50 zookeeper-3.4.14.jar.md5-rw-rw-r--. 1 2002 2002 41 Mar 6 11:50 zookeeper-3.4.14.jar.sha1drwxr-xr-x. 3 2002 2002 47 Mar 6 12:09 zookeeper-clientdrwxr-xr-x. 12 2002 2002 4096 Mar 6 12:09 zookeeper-contribdrwxr-xr-x. 7 2002 2002 4096 Mar 6 12:09 zookeeper-docsdrwxr-xr-x. 3 2002 2002 35 Mar 6 12:09 zookeeper-itdrwxr-xr-x. 4 2002 2002 46 Mar 6 12:09 zookeeper-jutedrwxr-xr-x. 5 2002 2002 176 Mar 6 12:09 zookeeper-recipesdrwxr-xr-x. 3 2002 2002 32 Mar 6 12:09 zookeeper-server$ mkdir data 进入data目录下创建myid文件,并在myid文件里添加一个标识数字1，每台服务器可以使用自增标识。比如：192.168.23.139使用数字1， 192.168.23.140使用数字2，192.168.23.141使用数字3.以此类推 12cd datavim myid 将zookeeper文件夹拷贝到其他服务器 是用scp拷贝到其他服务器，使用-r表示递归拷贝 12scp -r zookeeper-3.4.14/ root@192.168.23.140:/usr/local/scp -r zookeeper-3.4.14/ root@192.168.23.141:/usr/local/ 修改其他服务器上的myid文件 启动集群 在每台服务器上执行以下命令 1bin/zkServer.sh start 检查是否启动成功Zookeeper全部启动后查看Zookeeper状态 1234[root@node01 zookeeper-3.4.14]# bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper-3.4.14/bin/../conf/zoo.cfgMode: follower 错误如果没有启动请查看防火墙是否关闭 CentOS 7.0默认使用的是firewall作为防火墙 停止firewall1systemctl stop firewalld.service 禁止firewall开机启动1systemctl disable firewalld.service]]></content>
      <categories>
        <category>集群搭建</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何搭建Spring Cloud项目]]></title>
    <url>%2F2019%2F05%2F03%2F%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BASpring-Cloud%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[什么是Spring CloudSpring Cloud是一个分布式的整体解决方案。Spring Cloud 为开发者提供了在分布式系统（配置管理，服务发现，熔断，路由，微代理，控制总线，一次性token，全局琐，leader选举，分布式session，集群状态）中快速构建的工具，使用Spring Cloud的开发者可以快速的启动服务或构建应用、同时能够快速和云平台资源进行对接。 SpringCloud分布式开发五大常用组件 服务发现——Netflix Eureka 客服端负载均衡——Netflix Ribbon 断路器——Netflix Hystrix 服务网关——Netflix Zuul 分布式配置——Spring Cloud Config 测试如下：建立一个pom工程，工程中创建三个Module：eureka-server，eureka-consumer和provider-server。 建立pom工程 使用idea的工具栏 file -&gt; new -&gt; project 使用maven 创建pom工程。 将项目pom.xml里的packaging标签内容改成pom，使项目变成聚合工程。Spring boot版本最好是1.5.10.RELEASE，否则可能会出现不必要的报错。 建立eureka-server注册中心 在pom工程中创建一个Spring boot模块,名称为eureka-server 继承父类的pom，eureka-server的pom文件修改为： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.weijunzhe&lt;/groupId&gt; &lt;artifactId&gt;springcloud&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.weijunzhe&lt;/groupId&gt; &lt;artifactId&gt;eureka-server&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;eureka-server&lt;/name&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;description&gt;Spring cloud 注册中心&lt;/description&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Edgware.SR2&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt;&lt;/project&gt; application.yml修改为： 12345678910111213141516171819server: port: 8761spring: application: name: eureka-server # eureka实例的主机名eureka: instance: prefer-ip-address: true client: fetch-registry: false #不把自己注册到eureka上 register-with-eureka: false #不从eureka上来获取服务的注册信息--不检索服务 server: wait-time-in-ms-when-sync-empty: 0security: basic: enabled: true # 启用用户名和密码保护服务 user: # 注册服务使用的用户名和密码 name: admin password: admin 启动类加上EnableEurekaServer注解： 123456789101112131415package com.weijunzhe;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@EnableEurekaServer@SpringBootApplicationpublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerApplication.class, args); &#125;&#125; 启动注册中心项目，浏览器访问http://localhost:8761： 此时注册中心中还没有任何服务实例！ 创建服务提供者并进行注册 在pom工程中创建一个Springboot模块,名称为produce-server 继承父类的pom，produce-server的pom文件修改为 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.weijunzhe&lt;/groupId&gt; &lt;artifactId&gt;springcloud&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.weijunzhe&lt;/groupId&gt; &lt;artifactId&gt;produce-server&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;produce-server&lt;/name&gt; &lt;description&gt;Springcloud服务发布端&lt;/description&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Edgware.SR2&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;!--这里表明为客户端--&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.yml修改为： 12345678910111213server: port: 8001spring: application: name: produce-servereureka: client: registerWithEureka: true fetchRegistry: true serviceUrl: defaultZone: http://admin:admin@localhost:8761/eureka/ instance: prefer-ip-address: true # 注册服务的时候使用服务的ip地址 4.主程序类如下：123456789101112131415package com.weijunzhe;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;@SpringBootApplication@EnableDiscoveryClientpublic class ProduceServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ProduceServerApplication.class, args); &#125;&#125; 发布服务如下： service如下 1234567891011121314package com.weijunzhe.test.service.impl;import com.weijunzhe.test.service.TestService;import org.springframework.stereotype.Service;@Servicepublic class TestServiceImpl implements TestService &#123; @Override public String test(String username) &#123; System.out.println(&quot;欢迎您，&quot; + username); return &quot;欢迎您，&quot; + username; &#125;&#125; controller如下： 12345678910111213141516171819package com.weijunzhe.test.controller;import com.weijunzhe.test.service.TestService;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import javax.annotation.Resource;@RestControllerpublic class TestController &#123; @Resource TestService testService; @GetMapping(&quot;/test&quot;) public String test(String username)&#123; return testService.test(username); &#125;&#125; 启动服务提供者，然后查看浏览器注册中心页面： 此时注册中心中就有了服务提供者的一个实例！ 浏览器测试服务提供者如下： 创建服务消费者并注册和发现服务 在pom工程中创建一个Springboot模块,名称为eureka-server 继承父类的pom，eureka-server的pom文件修改为： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.weijunzhe&lt;/groupId&gt; &lt;artifactId&gt;springcloud&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.weijunzhe&lt;/groupId&gt; &lt;artifactId&gt;eureka-server&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;eureka-server&lt;/name&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;description&gt;Spring cloud 注册中心&lt;/description&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Edgware.SR2&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt;&lt;/project&gt; application.yml修改为： 12345678910111213141516171819server: port: 8761spring: application: name: eureka-server # eureka实例的主机名eureka: instance: prefer-ip-address: true client: fetch-registry: false #不把自己注册到eureka上 register-with-eureka: false #不从eureka上来获取服务的注册信息--不检索服务 server: wait-time-in-ms-when-sync-empty: 0security: basic: enabled: true # 启用用户名和密码保护服务 user: # 注册服务使用的用户名和密码 name: admin password: admin 启动类加上EnableEurekaServer注解： 123456789101112131415package com.weijunzhe;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@EnableEurekaServer@SpringBootApplicationpublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerApplication.class, args); &#125;&#125; 启动注册中心项目，浏览器访问http://localhost:8761/： 此时注册中心中还没有任何服务实例！ 创建服务提供者并进行注册 在pom工程中创建一个Springboot模块,名称为eureka-consumer 继承父类的pom，eureka-consumer的pom文件修改为 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.weijunzhe&lt;/groupId&gt; &lt;artifactId&gt;springcloud&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.weijunzhe&lt;/groupId&gt; &lt;artifactId&gt;eureka-consumer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;eureka-consumer&lt;/name&gt; &lt;description&gt;Spring Cloud 消费端&lt;/description&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Edgware.SR2&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.yml修改为： 123456789101112spring: application: name: consumer-userserver: port: 8200eureka: instance: prefer-ip-address: true # 注册服务的时候使用服务的ip地址 client: service-url: defaultZone: http://admin:admin@localhost:8761/eureka/ 4.主程序类如下：123456789101112131415161718192021222324package com.weijunzhe;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@SpringBootApplication@EnableDiscoveryClient //开启发现服务功能public class EurekaConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaConsumerApplication.class, args); &#125; @LoadBalanced //开启负载均衡机制 @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(); // 用来发送http请求 &#125;&#125; 发布服务如下： controller如下：这里需要注意手动往容器中注册了RestTemplate，其提供了多种便捷访问远程Http服务的方法，是一种简单便捷的访问restful服务模板类，是Spring提供的用于访问REST服务的客户端模板工具类。1234567891011121314151617181920package com.weijunzhe.test.controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;import javax.annotation.Resource;@RestControllerpublic class TestController &#123; @Resource RestTemplate restTemplate; @GetMapping(&quot;/test&quot;) public String test(String username)&#123; String msg = restTemplate.getForObject(&quot;http://produce-server/test?username=&quot; + username, String.class); return msg; &#125;&#125; 将服务消费者项目启动，查看浏览器注册中心： 访问服务消费者的方法(http://localhost:8200/test?username=admin2)： 参考文章https://blog.csdn.net/j080624/article/details/81004207]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Map如何实现线程安全]]></title>
    <url>%2F2019%2F01%2F29%2FMap%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%2F</url>
    <content type="text"><![CDATA[Java 提供了不同层面的线程安全支持。在传统集合框架内部，除了 Hashtable 等同步容器，还提供了所谓的同步包装器（Synchronized Wrapper），我们可以调用Collections 工具类提供的包装方法，来获取一个同步的包装容器（如 Collections.synchronizedMap），但是它们都是利用非常粗粒度的同步方式，在高并发情况下，性能比较低下。另外，更加普遍的选择是利用并发包提供的线程安全容器类，它提供了： 各种并发容器，比如 ConcurrentHashMap、CopyOnWriteArrayList。 各种线程安全队列（Queue/Deque），如 ArrayBlockingQueue、SynchronousQueue。 各种有序容器的线程安全版本等。 具体保证线程安全的方式，包括有从简单的 synchronize 方式，到基于更加精确细化的，比如基于分离锁实现的 ConcurrentHashMap 等并发实现等。具体选择要看开发的场景需求，总体来说，并发包内提供的容器通用场景，远优于早期的简单同步实现。 为什么需要 ConcurrentHashMap？ Hashtable 本身比较低效，因为它的实现基本就是将 put、get、size 等各种方法加上 “synchronized”。简单来说，这就导致了所有并发操作都要竞争同一把锁，一个线程在进行同步操作时，其他线程只能等待，大大降低了并发操作的效率。 前面已经提过 HashMap 不是线程安全的，并发情况会导致类似 CPU 占用 100%等一些问题，那么能不能利用 Collections 提供的同步包装器来解决问题呢？ 看看下面的代码片段，我们发现同步包装器只是利用输入 Map 构造了另一个同步版本，所有操作虽然不再声明成为 synchronized 方法，但是还是利用了 “this” 作为互斥的 mutex，没有真正意义上的改进！ 12345678910private static class SynchronizedMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Serializable &#123; private final Map&lt;K,V&gt; m; // Backing Map final Object mutex; // Object on which to synchronize // … public int size() &#123; synchronized (mutex) &#123;return m.size();&#125; &#125; // … &#125; 所以，Hashtable 或者同步包装版本，都只是适合在非高并发的场景下。 以上就是今天的总结。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对比Hashtable、HashMap和TreeMap的区别]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%AF%B9%E6%AF%94Hashtable%E3%80%81HashMap%E5%92%8CTreeMap%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[Map 是广义 Java 的集合框架中的另一部分，HashMap 作为框架中使用频率最高的类型之一，它本身以及相关类型自然也是面试考察的热点。 Hashtable、HashMap、TreeMap 都是最常见的一些 Map 实现，是以键值对的形式存储和操作数据的容器类型。 Hashtable 是早期 Java 类库提供的一个哈希表实现，本身是同步的，不支持 null 键和值，由于同步导致的性能开销，所以已经很少被推荐使用。 HashMap 是应用更加广泛的哈希表实现，行为上大致与 HashTable 一致，只要区别在于 HashMap 不是同步的，支持 null 键和值等。通常情况下，HashMap 进行 put 或者 get 操作，可以达到常数时间的性能，所以它是绝大部分利用键值对存储场景的首选，比如，实现一个用户 ID 和用户信息对应的运行时存储结构。 TreeMap 则是基于红黑树的一种提供顺序访问的 Map，和 HashMap 不同，它的 get、put、remove 之类操作都是O（log（n））的时间复杂度，具体顺序可以指定 Comparator 来决定，或者根据键的自然顺序来判断。 知识扩展首先，我们先对 Map 相关类型有个整体了解，Map 虽然通常被包括在 Java 集合框架里，但是其本身并不是狭义上的集合类型（Collection），具体可以参考下面这个简单类图。 Hashtable 比较特别，作为类似 Vector、Stack 的早期集合相关类型，它是扩展了Dictionary 类的，类结构上与 HashMap 之类明显不同。 HashMap 等其他 Map 实现则是都扩展了 AbstractMap，里面包含了通用方法抽象。不同Map 的用途，从类图结构就能体现出来，设计目的已经体现在不同的接口上。 大部分使用 Map 的场景，通常就是放入、访问或者删除，而对顺序没有特别要求，HashMap 在这种情况下基本是最好的选择。HashMap 的性能表现非常依赖于哈希码的有效性，请务必掌握 hashCode 和 equals 的一些基本约定，比如： equals 相等，hashCode 一定要相等。 重写了 hashCode 也要重写 equals。 ha’shCode 需要保持一致性，状态改变返回的哈希值仍然要一致。 equals 的对称、反射、传递等特性。 以上就是今天的总结。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对比Vector、ArrayList、LinkedList的区别]]></title>
    <url>%2F2019%2F01%2F25%2F%E5%AF%B9%E6%AF%94Vector%E3%80%81ArrayList%E3%80%81LinkedList%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[我们在日常的工作中，能够高效地管理和操作数据是非常重要的。由于每个编程语言支持的数据结构不尽相同，比如 C 语言，需要自己实现很多基础数据结构，管理和操作会比较麻烦。相比之下，Java 则要方便的多，针对通用场景的需求，Java 提供了强大的集合框架，大大提高了开发者的生产力。Verctor、ArrayList、LinkedList都是集合框架中的 List，也就是所谓的有序集合，因此具体功能也比较相近，比如都提供按照位置进行定位、添加或者删除的操作，都提供迭代器以遍历其内容等。但因为具体的设计区别，在行为、性能、线程安全等方面，表现又有很大不同。 Vector 是 Java 早期提供的线程安全的动态数组，如果不需要线程安全，并不建议选择，毕竟同步时有额外开销的。Vector 内部是使用对象数组来保存，可以根据需要自动增加容量，当数组已满时，会创建新的数组，并拷贝原有数组数据。 ArrayList 是应用更加广泛的动态数组实现，它本身不是线程安全的，所以性能要好很多。与 Vector 近似，ArrayList 也是可以根据需要调整容量，不过两者的调整逻辑有所区别，Vector 在扩容时会提高 1 倍，而 ArrayList 则是增加 50%。 LinkedList 顾名思义是 Java 提供的双向链表，所以它不需要像上面两种那样调整容量，它也不是线程安全的。 使用场景 Vector 和 ArrayList 作为动态数组，其内部元素以数组形式顺序存储的，所以非常适合随机访问的场合。除了尾部插入和删除元素，往往性能会相对较差，比如我们在中间位置插入一个元素，需要移动后续所有元素。 而 LinkedList 进行节点插入、删除却要高效得多，但是随机访问性能则要比动态数组慢。 所以，在应用开发中，如果事先可以估计到，应用操作是偏向于插入、删除，还是随机访问较多，就可以针对性的进行选择。 知识扩展为了有个直观的印象，下面展示一张简要的类图。注意，为了避免混淆，这里并没有把 java.util.concurrent 下面的线程安全容器添加进来；也没有列出 Map 容器，虽然通常概念上我们也会把 Map 作为集合框架的一部分，但是它本身并不是真正的集合（Collection）。 我们可以看到 Java 的集合框架，Collection 接口是所有集合的根，然后扩展开提供了三大类集合，分别是： List，也就是之前介绍最多的有序集合，它提供了方便的访问、插入、删除等操作。 Set，Set 是不允许重复元素的，这是和 List 最明显的区别，也就是不存在两个对象 equals 返回 true。我们日常开发中有很多需要保证元素唯一性的场合。 Queue/Deque，则是 Java 提供的标准队列结构的实现，除了集合的基本功能，他还支持类似先进先出（FIFO，First-In-First-Out）或者后进先出（LIFO，Last-In-First-Out）等特定行为。这里不包括 BlockingQueue，因为通常是并发编程场合，所以被放置在并发包里。 每种集合的通用逻辑，都被抽象到相应的抽象类之中，比如 AbStractList 就集中了各种 List 操作的通用部分。这些集合不是完全孤立的，比如，LinkedList 本身，既是 List，也是 Deque。 如果阅读过更多源码，你会发现，其实，TreeSet 代码里实际默认是利用 TreeMap 实现的，Java 类库创建了一个 Dummy 对象“PRIESENT” 作为 value，然后所有插入的元素其实是以键的形式放入了 TreeMap 里面；同理，HashSet 其实也是以 HashMap 为基础实现的，原来他们只是 Map 类的马甲！ 就像前面提到过的，我们需要对各种具体集合实现，至少了解基本特征和经典使用场景，以 Set 的几个实现为例： TreeSet 支持自然顺序访问，但是添加、删除、包含等操作要相对低效（时间）。 HashSet 则是利用哈希算法，理想情况下，如果哈希散列正常，可以提供常数时间的添加、删除、包含等操作，但是它不保证有序。 LinkedHashSet，内部构建了一个记录插入顺序的双向链表，因此提供了按照插入顺序遍历的能力，与此同时，也保证了常数时间的添加、删除、包含等操作，这些操作性能略低于 HashSet，因为需要维护链表的开销。 在遍历元素时，HashSet 性能受到自身容量影响，所以初始化时，除非有必要，不然不要将其背后的 HashMap 容量设置过大。而对于 LinkedHashSet，由于其内部链表提供的方便，遍历性能只和元素多少有关系。 以上就是今天的总结。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[int和Integer有什么区别]]></title>
    <url>%2F2019%2F01%2F24%2Fint%E5%92%8CInteger%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[java虽然号称是面向对象的语言，但是原始数据类型仍然是重要的组成元素，所以在面试中，经常考察原始数据类型和包装类等Java语言特性。int 是我们常说的整形数字，是 Java 的8个原始数据类型（Primitive Types，boolean、byte、short、int、float、double、long）之一。Java语言虽然号称一切都是对象，但是原始类型是例外。 Integer 是 int 对应的包装类，他有一个 int 类型的字段存储数据，并且提供了基本操作，比如数学运算、int和字符串之间转换等。在Java 5 中，引入了自动装箱和自动拆箱功能（boxing/unboxing），Java 可以根据上下文，自动进行转换，极大地简化了相关编程。 关于 Integer 的值缓存，这涉及 Java 5 中另一个改进。构建 Integer 对象的传统方式是直接调用构造器，直接 new 一个对象。但是根据实践，我们发现大部分数据操作都是集中在有限的、较小的数值范围，因而，在 Java 5 中新增了静态工厂方法 valueOf，在调用他的时候会利用一个缓存机制，带来了明显的性能改进。按照 Javadoc，这个值默认缓存是 -128 到 127 之间。 知识扩展理解自动装箱、拆箱自动装箱实际上算是一种语法糖。什么是语法糖？可以简单理解为 Java 平台为我们自动进行了一些转换，保证不同的写法在运行时等价，他们发生在编译阶段，也就是生成的字节码是一致的。 像前面提到的整数，javac 替我们自动把装箱转换为 Integer.valueOf()，把拆箱替换为 Integer.intValue()，这似乎也顺道回答了另一个问题，既然调用的是 Integer.valueOf()，自然能够得到缓存的好处啊。 如何程序化的验证上面的结论呢？ 你可以写一段简单的程序包含下面两句代码，然后反编译一下。当然，这是一种从表现倒推的方法，大多数情况下，我们还是直接参考规范文档会更加可靠，毕竟软件承诺的是遵循规范，而不是保持当前行为。12Integer integer = 1;int unboxing = integer ++; 反编译输出：12341: invokestatic #2 // Methodjava/lang/Integer.valueOf:(I)Ljava/lang/Integer;8: invokevirtual #3 // Methodjava/lang/Integer.intValue:()I 这种缓存机制并不是只有 Integer 才有，同样存在于其他的一些包装类，比如： Boolean，缓存了 true/false 对应实例，确切说，只会返回两个常量实例 Boolean.TRUE/FALSE。 Short，同样是缓存了 -128 到 127 之间的数值。 Byte，数值有限，所以全部都被缓存。 Character，缓存范围‘\u0000’ 到 ‘\u007F’。自动装箱/自动拆箱似乎很酷，在编程实践中，有什么需要注意的吗？ 原则上，建议避免无意中的装箱、拆箱行为，尤其是在性能敏感的场合，创建 10 万个 Java 对象和 10 万个整数的开销可不是一个数量级的，不管是内存使用还是处理速度，光是对象头的空间占用就已经是数量级的差距了。 以上就是今天的总结。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java反射机制与动态代理]]></title>
    <url>%2F2019%2F01%2F23%2FJava%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%E4%B8%8E%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[反射机制反射机制是 Java 语言提供的一种基础功能，赋予程序在运行时自省（introspect，官方用语）的能力。通过反射我们可以直接操作类或者对象，比如获取某个对象的类定义，获取类声明的属性和方法，调用方法或者构造对象，甚至可以运行时修改类定义。 动态代理动态代理是一种方便运行动态构建代理、动态处理代理调用的机制，很多场景都是利用类似机制做到的，比如用来包装RPC调用、面向切面的编程（AOP）。 实现动态代理的方式很多，比如 JDK 自身提供的动态代理，就是主要利用了上面提到的反射机制。还有其他的实现方式，比如利用传说中更高性能的字节码操作机制，类似 ASM、cglib（基于ASM）、javassist等。 首先，他是一个代理机制。如果熟悉设计模式中的代理模式，我们就会知道，代理可以看作对调用目标的一个包装，这样我们对目标代码的调用不是直接发生的，而是通过代理完成的。其实很多动态代理场景，我认为也可以看作是装饰器（Decorator）模式的应用。 通过代理可以然调用者与实现者之间解耦。比如进行RPC调用，框架内部的寻址、序列化、反序列化等，对于调用者往往是没有太大意义的，通过代理，可以提供更加友善的界面。 代理的发展经历了静态到动态的过程，源于静态代理引入的额外工作。类似早期的 RMI 之类古董技术，还需要 rmic 之类工具生成静态 stub 等各种文件，增加了很多繁琐的准备工作，而这又和我们的业务逻辑没有关系。利用动态代理机制，相应的 stub 等类，可以在运行时生成，对应的调用操作也是动态完成，极大地提高了我们的生产力。改进后的 RMI 已经不再需要手动去准备这些了，虽然它仍然时相对古老落后的技术，未来也许会逐步被移除。 代理的方式JDK 动态代理1234567891011121314151617181920212223242526272829303132public class MyDynamicProxy &#123; public static void main (String[] args) &#123; HelloImpl hello = new HelloImpl(); MyInvocationHandler handler = new MyInvocationHandler(hello); // 构造代码实例 Hello proxyHello = (Hello) Proxy.newProxyInstance(HelloImpl.class.getClassLoader(), HelloImpl.class.getInterfaces(), handler); // 调用代理方法 proxyHello.sayHello(); &#125;&#125;interface Hello &#123; void sayHello();&#125;class HelloImpl implements Hello &#123; @Override public void sayHello() &#123; System.out.println(&quot;Hello World&quot;); &#125;&#125; class MyInvocationHandler implements InvocationHandler &#123; private Object target; public MyInvocationHandler(Object target) &#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;Invoking sayHello&quot;); Object result = method.invoke(target, args); return result; &#125;&#125; 上面的JDK Proxy 例子，非常简单地实现了动态代理的构建和代理操作。首先，实现对应的 InvocationHandler；然后，以接口 Hello 为纽带， 为被调用目标构建代理对象，进而应用程序就可以使用代理对象间接运行调用目标的逻辑，代理为应用插入额外逻辑（这里时println）提供了便利的入口。 cglib动态代理cglib 动态代理采用的是创建目标类的子类的方式，因为是子类化，我们可以达到近似使用被调用者本身的效果。在Spring 编程中，框架通常会处理这种情况，当然我们也可以显式指定。 JDK Proxy 的优势： 最小化依赖关系，减少依赖意味着简化开发和维护，JDK 本身的支持，可能比 cglib 更加可靠。 平滑进行 JDK 版本升级，而字节码类库通常需求进行更新以保证在新版 Java 上能够使用。 代码实现简单。 基于类似cglib 框架的优势 有的时候调用目标可能不便实现额外接口，从某种角度看，限定调用者实现接口是有些侵入性的实践，类似 cglib 动态代理就没有这种限制。 只操作我们关心的类，而不必为其他相关类增加工作量。 高性能。 以上就是今天的总结。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[String、StringBuffer、StringBuilder的区别]]></title>
    <url>%2F2019%2F01%2F22%2FString%E3%80%81StringBuffer%E3%80%81StringBuilder%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[区别String 是 Java 语言非常基础和重要的类，提供了构造和管理字符串的各种基本逻辑。它是典型的Immutable类，被声明成为final class，所有属性也都是final的。也由于它的不可变性，类似拼接、裁剪字符串等动作，都会产生新的String对象。由于字符串操作的普遍性，所以相关操作的效率往往对应用性能有明显影响。StringBuffer 是为了解决上面提到的字符串拼接产生太多中间对象的问题而提供的一个类，我们可以用append 或者 add 方法，把字符串添加到已有序列的末尾或者指定位置。StringBuffer 本质是一个线程安全的可修改字符序列，它保证了线程安全，也随之带来了额外的性能开销，所以除非有线程安全的需要，不然还是推荐使用它的后继者，也就是StringBuilder。 StringBuilder 是 Java 1.5 中新增的， 在能力上和 StringBuffer 没有本质区别，但是它去掉了线程安全的部分，有效减少了开销，是绝大部分情况下进行字符串拼接的首选。 扩展 字符串的设计与实现考量String 是 Immutable 类的典型实现，原生的保证了基础线程安全，因为你无法对它内部数据进行任何修改，这种便利甚至体现在拷贝构造函数中，由于不可变，Immutable 对象在拷贝时不需要额外复制数据。 字符串缓存如果把常见应用进行堆转存（Dump Heap），然后分析对象组成，会发现平均25%的对象是字符串，并且其中约半数是重复的。如果能避免创建重复字符串，可以有效降低内存消耗和对象创建开销。 String自身的演化在Java的字符串历史版本中，它是使用char数组来存储数据的，这样非常直接。但是Java中的char是两个bytes大小，拉丁语系语言的字符，根本就不需要太宽的char，这样无区别的实现就造成了一定的浪费。密度是编程语言平台永恒的话题，因为归根结底绝大部分任务是要来操作数据的。 在Java 6 的时候，Oracle JDK 就提供了压缩字符串的特性，但是这个特性的实现并不是开源的，而是在实践中也暴露出了一些问题，所以在最新的JDK版本中已经将它移除了。 在 Java 9中，我们引入Compact Strings的设计，对字符串进行了大刀阔斧的改进。将数据存储方式从char数组，改变为一个byte数组加上一个标识编码的所谓coder，并且将相关字符串操作类都进行了修改。另外，所有相关的Intrinsic之类也都进行了重写，以保证没有任何性能损失。 当然，在极端情况下，字符串也出现了一些能力退化，比如最大字符串的大小。可以思考下，原来char数组的实现，字符串的最大长度就是数组本身的长度限制，但是替换成byte数组，同样数组长度下，存储能力是退化了一倍的！还好这是存在于理论上的极限，还没有发现现实应用受此影响。 在通用的性能测试和产品实验中，我们能非常明显地看到紧凑字符串带来的优势，更小的内存占用、更快的 操作速度。 以上就是今天的总结。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[强引用、软引用、弱引用、幻象引用有什么区别]]></title>
    <url>%2F2019%2F01%2F21%2F%E5%BC%BA%E5%BC%95%E7%94%A8%E3%80%81%E8%BD%AF%E5%BC%95%E7%94%A8%E3%80%81%E5%BC%B1%E5%BC%95%E7%94%A8%E3%80%81%E5%B9%BB%E8%B1%A1%E5%BC%95%E7%94%A8%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[不同的引用类型，主要体现的是对象不同的可达性（reachable）状态和对垃圾收集的影响。所谓强引用（“Strong” Refrence），就是我们最常见的普通对象引用，只要还有强引用指向一个对象，就能表明对象还“活着”，垃圾收集器不会碰这种对象。对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为null，就是可以被垃圾收集的了，当然具体回收时机还是要看垃圾收集策略。 软引用（SoftReference），是一种相对强引用弱化一些的引用，可以让对象豁免一些垃圾收集，只有当JVM认为内存不足时，才会去试图回收软引用指向的对象。JVM会确保在抛出OutOfMemoryError之前，清理软引用指向的对象。软引用通常用来实现内存敏感的缓存，如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。 弱引用（WeakReference）并不能使对象豁免垃圾收集，仅仅是提供一种访问在弱引用状态下对象的途径。这就可以用来构建一种没有特定约束的关系，比如，维护一种非强制性的映射关系，如果试图获取时时对象还在，就是用它，否则重现实例化。它同样是很多缓存实现的选择。 对于幻象引用，有时候也翻译成虚引用，你不能通过它访问对象。幻象引用仅仅是提供一种确保对象被finalize以后，做某些事情的机制，比如，通常用来做所谓的Post-Mortem 清理机制，Java平台自身 Cleaner 机制里，也有人利用幻象引用监控对象的创建和销毁。 知识扩展 对象可达性状态流转分析 首先，请看下面的流程图，这里简单总结了对象生命周期和不同可达性状态，以及不同状态可能达到改变关系，可能未必100%严谨，来阐述下可达性的变化。 上图是Java 定义的不同可达性级别（reachability level），具体如下： 强可达（Strongly Reachable），就是当一个对象可以有一个或多个线程可以不通过各种引用访问到的情况。比如，我们新创建一个对象，那么创建它的线程对它就是强可达。 软可达（Softly Reachable），就是当我们只能通过软引用才能访问到对象的状态。 弱可达（Weakly Reachable），类似前面提到的，就是无法通过强引用或者软引用访问，只能通过弱引用访问时的状态。这是十分临近finalize状态的时机，当弱引用被清除的时候，就符合finalize的条件了。 幻象可达（Phantom Reachable），上面流程图已经很直观了，就是没有强、软、弱引用关联，并且finalize过了，只有幻象引用指向这个对象的时候。 当然，还有最后的状态，就是不可达（unreachable），意味着对象可以被清除了。 判断对象可达性，是JVM垃圾收集器决定如何处理对象的一部分考虑。 以上就是今天的总结。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[final、finally、finalize的区别]]></title>
    <url>%2F2019%2F01%2F18%2Ffinal%E3%80%81finally%E3%80%81finalize%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[final 可以用来修饰类、方法、变量，分别有着不同的意义，final 修饰的class代表不能被继承、final 修饰的方法表示不能被重写，final 修饰的变量表示不能被修改。 finally 则是java保证重点代码一定被执行的一种机制。我们可以使用 try-finally 或者 try-catch-finally 来进行类似关闭JDBC连接、保证unlock锁等动作。 finalize 是基础类java.lang.Object的一个方法，它的设计目的是保证对象在垃圾收集之前完成特定资源的回收。finalize机制已经不被推荐使用了，并且在JDK 9中被标记为deprecated。 适用场景final 我们可以将方法或者类声明成 final,这样就可以明确告诉别人，这些行为是不允许修改的。在java.lang包下面的很多类，相当一部分已经被声明成final class，在第三方类库的一些基础类中同样如此，这样能有效避免API的使用者更改一些基础功能，在某种意义上讲，这是保证平台安全的必要手段。 使用final修饰参数或者变量，也可以清楚地避免意外赋值导致的编程错误，甚至，有些人明确推荐将所有方法参数、本地变量、成员变量声明成final。 final变量产生了某种程度的不可变（immutable）的效果，所以，可以用于保护只读数据，尤其是在并发编程中，因为明确地不能再赋值final变量，有利于减少额外的同步开销，也可以省去一些防御性拷贝的必要。 final 也许会有性能上的好处，但是从开发实践的角度，除非有特别的考虑，不然最好不要指望这种小技巧带来所谓的性能好处，程序最好是体现它的语义目的。 finally对于finally，明确知道怎么使用就足够了。需要关闭的连接等资源，更推荐使用Java 7中添加的try-with-resources语句，因为通常Java平台能够更好地处理异常情况，编码量也要少很多，何乐而不为呢？ 另外，有一些偏门的finally问题也会被问到，比如：123456try &#123; // do something System.exit(1);&#125; finally&#123; System.out.println(“Print from finally”);&#125; 上面的finally里面的代码是不会被执行的，这是一个特例。 finalizefinalize 的执行时和垃圾收集关联在一起的，一旦实现了非空的 finalize 方法，就会导致相应的对象回收呈现数量级上的变慢，有人专门做过 benchmark，大概是 40-50 倍的下降。因为，finalize 被设计成在对象被垃圾收集前调用，这意味着实现了 finalize 方法的对象是个“特殊公民”，JVM 要对它进行额外处理。finalize 本质上成为了快速回收的阻碍者，可能导致你的对象经过多个垃圾收集周期才能被回收。 拓展 final不是 immutable！12345final List&lt;String&gt; strList = new ArrayList&lt;&gt;();strList.add(&quot;Hello&quot;);strList.add(&quot;world&quot;); List&lt;String&gt; unmodifiableStrList = List.of(&quot;hello&quot;, &quot;world&quot;);unmodifiableStrList.add(&quot;again&quot;); final 只能约束strList这个引用不可被赋值，但是strList 对象行为不被 final 影响，添加元素等操作是完全正常的。如果我们真的希望对象本身是不可变的，那么需要相应的类支持不可变的行为。在上面的这个例子中，List.of方法创建的本身就是不可变的 List，最后那句 add 是会在运行时抛出异常的。 以上就是今天的总结。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Throwable、Error、Exception的区别]]></title>
    <url>%2F2019%2F01%2F17%2FThrowable%E3%80%81Error%E3%80%81Exception%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[理解throwable、error、exceptionexception 和 error 都继承了throwable类，在Java中只有继承了throwable类型的实例才可以被抛出（throw）或着捕获（catch），他是异常处理的基本处理类型。exception 和 error 体现了Java平台设计者对不同异常情况的分类。exception 是程序运行时异常，可以预料的意外情况，可能并应该被捕获，进行相应处理。 error是指在正常情况下，不大可能出现的情况，绝大部分的error都会导致程序（比如jvm自身）处于非正常、不可恢复的状态。既然是在非正常情况下，所以不便于也不需要捕获，常见的比如OutOfMemoryError之类，都是error的子类。 exception 又分为可检查（check）异常和不可检查（unchecked）异常，可检查异常必须在源代码中显式的捕获异常，这是编译器检查的一部分。不可检查的error，是Throwable 不是exception。 不检查异常就是所谓的运行时异常，类似于 NullPointerException、ArrayIndexOutOfBoundsException 之类，通常是编码可以避免的逻辑错误，具体根据需要来判断是否需要捕获，并不会在编译期强制要求。 throwable、error、exception关系图 拓展 下面代码有什么不当之处？1234567 try &#123; // 业务代码 // … Thread.sleep(1000L);&#125; catch (Exception e) &#123; // Ignore it&#125; 这段代码违反了两个原则。 尽量不要捕获类似于 Exception 这样的通用异常，而是应该捕获特定的异常，这里thread.sleep() 抛出的应该是InterruptedException。 不要生吞（swallow）异常。这是异常处理中要特别注意的事情，因为很可能导致出现非常难以诊断的诡异情况。 以上就是今天的总结。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[知识图谱相关资料整理]]></title>
    <url>%2F2019%2F01%2F16%2F%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[知识图谱 https://blog.csdn.net/nlphacker/article/details/39455663https://www.jianshu.com/p/4f09043e22ea?from=timelinehttps://blog.csdn.net/richgene/article/details/80481044https://www.jiqizhixin.com/articles/2018-06-20-4?tdsourcetag=s_pctim_aiomsg数学识别https://edu.aliyun.com/course/26?spm=a2c0j.103967.772922.1.7402ed64U28fhB 知识图谱相关 百度AI视频 https://ai.baidu.com/support/video scikit开发文档 http://cwiki.apachecn.org/pages/viewpage.action?pageId=10031359http://cwiki.apachecn.org/pages/viewpage.action?pageId=10031359 基本概念 https://blog.csdn.net/wyqwilliam/article/details/81676785 小白学数据分析 关联分析理论篇 http://blog.sina.cn/dpool/blog/s/blog_13bb711fd0102wcwl.html 基于Python的机器学习实战：Apriori https://www.cnblogs.com/90zeng/p/apriori.html#contents Python文章相关性分析—金庸武侠小说分析 http://m.mamicode.com/info-detail-2159455.html 相关文章 【Python金融量化】财经新闻文本分析 新闻联播文字版手机版 数据思维实践 | TASK 12 文本分析 数据思维实践 | TASK 12 文本分析]]></content>
      <categories>
        <category>python机器学习</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F01%2F01%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment 123456789101112131415&lt;div id=&quot;container&quot;&gt;&lt;/div&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://imsun.github.io/gitment/style/default.css&quot;&gt;&lt;script src=&quot;https://imsun.github.io/gitment/dist/gitment.browser.js&quot;&gt;&lt;/script&gt;&lt;script&gt;var gitment = new Gitment(&#123; id: &apos;页面 ID&apos;, // 可选。默认为 location.href owner: &apos;你的 GitHub ID&apos;, repo: &apos;存储评论的 repo&apos;, oauth: &#123; client_id: &apos;你的 client ID&apos;, client_secret: &apos;你的 client secret&apos;, &#125;,&#125;)gitment.render(&apos;container&apos;)&lt;/script&gt;]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
</search>
